{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Model Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function to calculate and return the Euclidean distance of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eucillidean_Distance(row1, row2):\n",
    "    Euc_D = np.sqrt(np.sum((row1-row2)**2))\n",
    "    return Euc_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function to calculate and return the Manhattan distance of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manhatten_Distance (row1,row2):\n",
    "    return np.sum(np.absolute(row1 - row2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function to calculate and return the accuracy and generalization error of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_and_error (a, b):\n",
    "    TP, TN , FP , FN = confusion_matrix(a,b)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    error = 1- accuracy \n",
    "    return (accuracy, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write three functions to compute: precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(a, b):\n",
    "    TP, TN , FP , FN = confusion_matrix(a,b)\n",
    "    if TP + FP == 0:\n",
    "        return 0 \n",
    "    else: \n",
    "        return TP / (TP + FP)\n",
    "    \n",
    "def recall(a, b):\n",
    "    TP, TN , FP , FN = confusion_matrix(a,b)\n",
    "    if TP + FN == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return TP / (TP + FN)\n",
    "def F1Score(a,b):\n",
    "    TP, TN , FP , FN = confusion_matrix(a,b)\n",
    "    return (TP)/(TP+((FN+FP)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function to compute the confusion matrix of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(a, b):\n",
    "    #A = predicted , b = truth label \n",
    "    TP = 0 \n",
    "    TN = 0\n",
    "    FP = 0 \n",
    "    FN = 0 \n",
    "    z = 0 \n",
    "    while z <= (len(a)-1):\n",
    "        if a[z] == 0 and b[z] == 0:\n",
    "            TN += 1\n",
    "        elif a[z] == 0 and b[z] == 1:\n",
    "            FN += 1\n",
    "        elif a[z] == 1 and b[z] == 0:\n",
    "            FP += 1\n",
    "        elif a[z] == 1 and b[z] == 1:\n",
    "            TP += 1\n",
    "        z += 1\n",
    "    return TP, TN , FP , FN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a function to generate the Receiver Operating Characteristic (ROC) curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_Curve (a,b):\n",
    "    Roc_Curves = {}\n",
    "    for values in a:\n",
    "        y_pred, y_test, y_prob = a[values]\n",
    "        roc_point = []\n",
    "        for threshold in b:\n",
    "            New_predict = predict_threshold(y_prob,threshold)\n",
    "            TPR = recall(New_predict, y_test)\n",
    "            FPR = FalsePostiveRate(New_predict, y_test)\n",
    "            roc_point.append([FPR, TPR])\n",
    "        Roc_Curves[values] = roc_point\n",
    "    return Roc_Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a function to compute area under curve (AUC) for the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Area_Under_Curve(a):\n",
    "    Auc_values = []\n",
    "    for values in a:\n",
    "        b = a[values]\n",
    "        AUC = 0\n",
    "        i = 0\n",
    "        while i <= (len(b)-2):\n",
    "            P1 = b[i]\n",
    "            P2 = b[i+1]\n",
    "            X_P1 = P1[0]\n",
    "            Y_P1 = P1[1]\n",
    "            X_P2 = P2[0]\n",
    "            Y_P2 = P2[1]\n",
    "            Triangle = (((Y_P1 - Y_P2)* (X_P1 - X_P2))/2)\n",
    "            Rectangle = (Y_P2 * (X_P1 - X_P2))\n",
    "            AUC += (Triangle + Rectangle)\n",
    "            i += 1\n",
    "        Auc_values.append(AUC)\n",
    "    return Auc_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a function to generate the precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Recall_Curve (a, b):\n",
    "    PR_Curves = {}\n",
    "    for values in a:\n",
    "        y_pred, y_test, y_prob = a[values]\n",
    "        PR_point = []\n",
    "        for threshhold in b:\n",
    "            y_prediction = predict_threshold(y_prob,threshhold)\n",
    "            Prec = precision(y_prediction , y_test)\n",
    "            Recall = recall (y_prediction , y_test)\n",
    "            PR_point.append ([Recall,Prec])\n",
    "        PR_Curves[values] = PR_point\n",
    "    return PR_Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. implement a KNN_Classifier model class. It should have the following three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classifier(): \n",
    "    def fit(self,X,y,n_neighbor,weights):#kwargss):\n",
    "        self.y = y # 1D targer vector\n",
    "        self.X = X # Data Matrix containing all features excluding the targe\n",
    "        self.n_neighbors = n_neighbor\n",
    "        self.weights = weights\n",
    "    def predict(self,X):\n",
    "        if self.weights == \"uniform\":\n",
    "            print(\"Uniform\")\n",
    "            x_test, x_train, y_test, y_train = partition (X,self.y,0.8)\n",
    "\n",
    "            x_train = x_train.to_numpy()\n",
    "\n",
    "            x_test = x_test.to_numpy()\n",
    "\n",
    "            y_train = y_train.to_numpy()    \n",
    "            y_test = y_test.to_numpy()\n",
    "            y_test = y_test.astype(np.int)      \n",
    "            y_train = y_train.astype(np.int)\n",
    "\n",
    "\n",
    "            num_test = x_test.shape[0]\n",
    "            num_train = x_train.shape[0]\n",
    "            distances = np.zeros((num_test,num_train))\n",
    "            for i in range(num_test):\n",
    "                for j in range(num_train):\n",
    "                    distances[i,j] = Eucillidean_Distance(x_test[i,:],x_train[j,:])\n",
    "            predict_test = distances.shape[0]\n",
    "            y_pred = np.zeros(predict_test)\n",
    "            y_prob = np.zeros(predict_test)\n",
    "\n",
    "            if self.n_neighbors == 1:\n",
    "                y_distances = np.argsort(distances)[:self.n_neighbors]\n",
    "                y_indicies = (np.argsort(distances)[self.n_neighbors])\n",
    "                k_closes_classes = y_train_[y_indicies]\n",
    "                y_pred = k_closes_classes\n",
    "                y_prob = k_closes_classes\n",
    "            else:\n",
    "                y_distances = np.sort(distances)\n",
    "                y_indicies = np.argsort(distances)\n",
    "                for t in range(num_test):\n",
    "\n",
    "                    k_closes_classes = y_train[y_indicies[t,:self.n_neighbors]]\n",
    "\n",
    "                    y_pred[t] = np.argmax(np.bincount((k_closes_classes)))\n",
    "                    if y_pred[t] == 1.0:\n",
    "                        number_of_values = (np.bincount(k_closes_classes == 1)[1])\n",
    "                        y_prob[t] = number_of_values / self.n_neighbors\n",
    "\n",
    "                    else:\n",
    "                        number_of_values = (np.bincount(k_closes_classes == 0)[0])\n",
    "                        y_prob[t] = number_of_values / self.n_neighbors\n",
    "            return y_pred, y_test, y_prob\n",
    "        else:\n",
    "            print(\"distance\")\n",
    "            X = shuffle.drop(labels='new quality_1', axis=1)\n",
    "            x_test, x_train, y_test, y_train = partition (X,self.y,0.2)\n",
    "\n",
    "            x_train = x_train.to_numpy()\n",
    "            x_test = x_test.to_numpy()\n",
    "\n",
    "            y_train = y_train.to_numpy()    \n",
    "            y_test = y_test.to_numpy()\n",
    "            y_test = y_test.astype(np.int)      \n",
    "            y_train = y_train.astype(np.int)\n",
    "\n",
    "\n",
    "            num_test = x_test.shape[0]\n",
    "            num_train = x_train.shape[0]\n",
    "            distances = np.zeros((num_test,num_train))\n",
    "            for i in range(num_test):\n",
    "                for j in range(num_train):\n",
    "                    distances[i,j] = Eucillidean_Distance(x_test[i,:],x_train[j,:])\n",
    "                    \n",
    "            \n",
    "            predict_test = distances.shape[0]\n",
    "            y_pred = np.zeros(predict_test)\n",
    "            y_prob = np.zeros(predict_test)\n",
    "            y_distances_ = (np.sort(distances))\n",
    "            y_indicies = (np.argsort(distances))\n",
    "            for t in range(num_test):\n",
    "                freq1_Eu = 0\n",
    "                freq2_Eu = 0\n",
    "                k_closes_classes = y_train[y_indicies[t,:self.n_neighbors]]\n",
    "                                            \n",
    "                for z in range ((len(k_closes_classes))):\n",
    "                    if k_closes_classes[z] == 0:\n",
    "                        freq1_Eu += 1/y_distances_[z,t]\n",
    "                    else:\n",
    "                        freq2_Eu += 1/y_distances_[t,z]\n",
    "                            \n",
    "                if np.sum(freq1_Eu) > np.sum(freq2_Eu):\n",
    "                    y_pred[t] = 0\n",
    "                else:\n",
    "                    y_pred[t] = 1\n",
    "                y_prob [t] = freq2_Eu / (freq1_Eu + freq2_Eu )\n",
    "            return y_pred, y_test, y_prob\n",
    "        \n",
    "#I've made this extra method, in order to do part Correctly. This is the same overall means of answering as \n",
    "#the regular predict method, but instead there is an extra loop in there that will be used to run through the \n",
    "#different number of folds avaiable. \n",
    "    def predict_folds(self, X, num_folds):\n",
    "        if self.weights == \"uniform\":\n",
    "            print (\"Uniform\")\n",
    "            Stored_dictionary_Euic = {}\n",
    "            Stored_dictionary_Ma = {}\n",
    "            for i in range(num_folds): \n",
    "                #because the folds don't change no matter how many times you recall this function\n",
    "                #I can just re use it each fold, and just take a different version of it from \n",
    "                # the features and labels\n",
    "                print(i)\n",
    "                features, labels =  folds(X,self.y,num_folds)\n",
    "                x_test = features[i]\n",
    "                del features[i]\n",
    "                x_train = pd.concat(features)\n",
    "                y_test = labels[i]\n",
    "                del labels[i]\n",
    "                y_train = pd.concat(labels)\n",
    "                #Above code is used to get the different fold into the specific training and test values\n",
    "\n",
    "                #had to confert these to arrays because some of the later on code wasn't working well\n",
    "\n",
    "                x_train = x_train.to_numpy()\n",
    "                x_test = x_test.to_numpy()\n",
    "                y_train = y_train.to_numpy()\n",
    "                y_test = y_test.to_numpy()\n",
    "\n",
    "                y_train = y_train.astype(np.int)\n",
    "                y_test = y_test.astype(np.int)\n",
    "\n",
    "                num_test = x_test.shape[0]\n",
    "                num_train = x_train.shape[0]\n",
    "                # These were created in order to put their values in a specific spot so that \n",
    "                #i can recall their index's to figure out the actual value from the training labels\n",
    "\n",
    "                distances_Eu = np.zeros((num_test,num_train))\n",
    "                distances_Ma = np.zeros((num_test,num_train))\n",
    "                for a in range(num_test):\n",
    "                    for j in range(num_train):\n",
    "                        distances_Eu[a,j] = Eucillidean_Distance(x_test[a,:],x_train[j,:])\n",
    "                        distances_Ma[a,j] = Manhatten_Distance(x_test[a,:],x_train[j,:])\n",
    "                y_pred_Eu = np.zeros(num_test)\n",
    "                y_pred_Ma = np.zeros(num_test)\n",
    "                y_prob_Eu = np.zeros(num_test)\n",
    "                y_prob_Ma = np.zeros(num_test)\n",
    "                y_distances_Eu = (np.sort(distances_Eu))\n",
    "                y_distances_Ma = (np.sort(distances_Ma))\n",
    "                y_indicies_Eu = np.argsort(distances_Eu)\n",
    "                y_indicies_Ma = np.argsort(distances_Ma)\n",
    "                for z in range(num_test):\n",
    "                    k_closes_classes_Eu = y_train[y_indicies_Eu[z, :self.n_neighbors]].astype(int)\n",
    "                    k_closes_classes_Ma = y_train[y_indicies_Ma[z,:self.n_neighbors]].astype(int)\n",
    "\n",
    "                    y_pred_Eu[z] = np.argmax(np.bincount(k_closes_classes_Eu))\n",
    "                    y_pred_Ma[z] = np.argmax(np.bincount(k_closes_classes_Ma))\n",
    "                    #I can use this to calculate the prediction just because the bianry is \n",
    "                    #0's and 1's i am calculating the probability of getting 1 everytime which is \n",
    "                    # just the sum of 1 / by the number of values within that instance\n",
    "                    y_prob_Eu[z] = (np.mean(k_closes_classes_Eu))\n",
    "\n",
    "                    y_prob_Ma[z] = (np.mean(k_closes_classes_Ma))\n",
    "                #We then store that value into a dictionary which has within it the prediction, \n",
    "                #the labels, as well as the prob for 1.\n",
    "\n",
    "                Stored_dictionary_Ma [i] = y_pred_Ma ,y_test, y_prob_Ma\n",
    "                Stored_dictionary_Euic [i] = y_pred_Eu,y_test, y_prob_Eu\n",
    "\n",
    "\n",
    "\n",
    "                # Then it returns both values for both Euic as well as Ma. Although it was said that\n",
    "                # we decdied what we wanted earlier. I left this in because it asked for it to test\n",
    "                #Both values and to see if antyhing changes because of it. \n",
    "            return Stored_dictionary_Euic, Stored_dictionary_Ma\n",
    "        else:\n",
    "            print(\"Distance\")\n",
    "            Stored_dictionary_Euic = {}\n",
    "            Stored_dictionary_Ma = {}\n",
    "            #Same thing as the other function above just with weight on the distance.\n",
    "            for i in range(num_folds):  \n",
    "                print(i)\n",
    "                features, labels =  folds(X,self.y,num_folds)\n",
    "                x_test = features[i]\n",
    "                del features[i]\n",
    "                x_train = pd.concat(features)\n",
    "                y_test = labels[i]\n",
    "                del labels[i]\n",
    "                y_train = pd.concat(labels)\n",
    "\n",
    "\n",
    "                x_train = x_train.to_numpy()\n",
    "                x_test = x_test.to_numpy()\n",
    "                y_train = y_train.to_numpy()\n",
    "                y_test = y_test.to_numpy()\n",
    "\n",
    "                y_train = y_train.astype(np.int)\n",
    "                y_test = y_test.astype(np.int)\n",
    "\n",
    "\n",
    "                num_test = x_test.shape[0]\n",
    "                num_train = x_train.shape[0]\n",
    "\n",
    "\n",
    "                distances_Eu = np.zeros((num_test,num_train))\n",
    "                distances_Ma = np.zeros((num_test,num_train))\n",
    "\n",
    "                for a in range(num_test):\n",
    "                    for j in range(num_train):\n",
    "                        distances_Eu[a,j] = Eucillidean_Distance(x_test[a,:],x_train[j,:])\n",
    "                        distances_Ma[a,j] = Manhatten_Distance(x_test[a,:],x_train[j,:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                predict_test = distances_Eu.shape[0]\n",
    "                y_pred_Eu = np.zeros(predict_test)\n",
    "                y_prob_Eu = np.zeros(predict_test)\n",
    "                y_pred_Ma = np.zeros(predict_test)\n",
    "                y_prob_Ma = np.zeros(predict_test)\n",
    "\n",
    "                y_distances_Eu = (np.sort(distances_Eu))\n",
    "                y_indicies_Eu = (np.argsort(distances_Eu))\n",
    "\n",
    "                y_distances_Ma = (np.sort(distances_Ma))\n",
    "                y_indicies_Ma = (np.argsort(distances_Ma))\n",
    "\n",
    "                # a loop to calculate the weight for each instance. \n",
    "\n",
    "                for z in range(num_test):\n",
    "                    k_closes_classes_Eu = y_train[y_indicies_Eu[z,:self.n_neighbors]]\n",
    "                    k_closes_classes_Ma = y_train[y_indicies_Ma[z,:self.n_neighbors]]\n",
    "                    freq1_Eu = 0\n",
    "                    freq2_Eu = 0\n",
    "                    freq1_Ma = 0\n",
    "                    freq2_Ma = 0\n",
    "                    #it looks for each value in the K neighbors labels, i can now figures out \n",
    "                    # which value to add to which varriable defined as freq 1 freq2. \n",
    "                    # freq 1 is the sum of 0 for that k neighbors, and freq 2 is the sum\n",
    "                    # of 1 for that neighbor. \n",
    "                    for t in range((len(k_closes_classes_Ma))):\n",
    "                        if k_closes_classes_Ma[t] == 0:\n",
    "                            freq1_Ma += 1/ y_distances_Ma[z,t]\n",
    "                        else:\n",
    "                            freq2_Ma += 1/ y_distances_Ma[z,t]\n",
    "\n",
    "                        if k_closes_classes_Eu[t] == 0:\n",
    "                            freq1_Eu += 1/y_distances_Eu[z,t]\n",
    "                        else:\n",
    "                            freq2_Eu += 1/y_distances_Eu[z,t]\n",
    "                    #then you decide which is larger, and you can then put the prediction down\n",
    "                    #based upon the values of those freq1 and freq2. \n",
    "                    if np.sum(freq1_Eu) > np.sum(freq2_Eu):\n",
    "                        y_pred_Eu[z] = 0\n",
    "                    else:\n",
    "                        y_pred_Eu[z] = 1\n",
    "\n",
    "                    if np.sum(freq1_Ma) > np.sum(freq2_Ma):\n",
    "                        y_pred_Ma[z] = 0\n",
    "                    else:\n",
    "                        y_pred_Ma[z] = 1\n",
    "                    y_prob_Eu [z] = freq2_Eu / (freq1_Eu + freq2_Eu )\n",
    "                    y_prob_Ma [z] = freq2_Ma / (freq1_Ma + freq2_Ma )\n",
    "\n",
    "\n",
    "                Stored_dictionary_Euic [i] = y_pred_Eu,y_test ,y_prob_Eu\n",
    "                Stored_dictionary_Ma [i] = y_pred_Ma, y_test, y_prob_Ma\n",
    "            return Stored_dictionary_Euic, Stored_dictionary_Ma\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Read in the winequality-white.csv file as a Pandas data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('winequality-white.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. The target will be the “quality” column which represents rating of wine and ranges from 3 to 8. You will need to convert it into a two-category variable consisting of “good” (quality > 5) & “bad” (quality <= 5). Your target vector should have 0s (representing “bad” quality wine) and 1s (representing “good” quality wine). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['quality'] > 5, 'new quality'] = '1'\n",
    "df.loc[df['quality'] <= 5, 'new quality'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Use the techniques from the first recitation to summarize each of the variables in the dataset in terms of mean, standard deviation, and quartiles. Include this in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Shuffle the rows of your data. You can use def = df.sample(frac=1) as an idiomatic way to shuffle the data in Pandas without losing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality                 1.000000\n",
       "alcohol                 0.435575\n",
       "pH                      0.099427\n",
       "sulphates               0.053678\n",
       "free sulfur dioxide     0.008158\n",
       "citric acid            -0.009209\n",
       "residual sugar         -0.097577\n",
       "fixed acidity          -0.113663\n",
       "total sulfur dioxide   -0.174737\n",
       "volatile acidity       -0.194723\n",
       "chlorides              -0.209934\n",
       "density                -0.307123\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['quality'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Name: new quality\n",
      "1    3258\n",
      "0    1640\n",
      "Name: new quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        print('\\nColumn Name:', col,)\n",
    "        print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = df.select_dtypes(['object'])\n",
    "dummy_df = pd.get_dummies(category_df)\n",
    "dummy_df['new quality'] = df['new quality']\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Generate pair plots using the seaborn package. This will be used to identify and report the redundant features, if there is any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### i did take this from the workbooks.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 24)\n",
    "    \n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.5, as_cmap=True)\n",
    "\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "# Pair grid set up\n",
    "g = sns.PairGrid(df)\n",
    "\n",
    "# Scatter plot on the upper triangle\n",
    "g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# Distribution on the diagonal\n",
    "g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# Density Plot and Correlation coefficients on the lower triangle\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "g.map_lower(corrfunc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Drop the redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['new quality_0','quality'], axis = 1) \n",
    "most_correlated = df.corr().abs()['new quality_1'].sort_values(ascending=False)\n",
    "most_correlated1 = most_correlated[:6]\n",
    "df = df.loc[:,most_correlated1.index]\n",
    "df = df.drop_duplicates(keep= 'first')\n",
    "## i ended up dropping every value that wasn't within the top 6 spot of correlation, just because \n",
    "## of how low those corelations were, they were below 0.1 almost reaching 0. \n",
    "## but i ddin't drop any based upon the pairs plot just becuase no one value was exactly the same as the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = df\n",
    "y = shuffle['new quality_1'] # 1D targer vector\n",
    "X = shuffle.drop(labels='new quality_1', axis=1)\n",
    "X_standardize = X.apply(lambda x: (x - x.mean(axis = 0) ) / (np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new quality_1</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>density</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3938.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "      <td>3938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.659726</td>\n",
       "      <td>10.590299</td>\n",
       "      <td>0.993788</td>\n",
       "      <td>0.280387</td>\n",
       "      <td>0.045923</td>\n",
       "      <td>137.160361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473861</td>\n",
       "      <td>1.215643</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.103227</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>43.019883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.991613</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>0.993490</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       new quality_1      alcohol      density  volatile acidity    chlorides  \\\n",
       "count    3938.000000  3938.000000  3938.000000       3938.000000  3938.000000   \n",
       "mean        0.659726    10.590299     0.993788          0.280387     0.045923   \n",
       "std         0.473861     1.215643     0.002900          0.103227     0.023160   \n",
       "min         0.000000     8.000000     0.987110          0.080000     0.009000   \n",
       "25%         0.000000     9.500000     0.991613          0.210000     0.035000   \n",
       "50%         1.000000    10.400000     0.993490          0.260000     0.042000   \n",
       "75%         1.000000    11.400000     0.995707          0.330000     0.050000   \n",
       "max         1.000000    14.200000     1.038980          1.100000     0.346000   \n",
       "\n",
       "       total sulfur dioxide  \n",
       "count           3938.000000  \n",
       "mean             137.160361  \n",
       "std               43.019883  \n",
       "min                9.000000  \n",
       "25%              106.000000  \n",
       "50%              133.000000  \n",
       "75%              166.000000  \n",
       "max              440.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Write a function named “partition” to split your data into trainingand test set. The function should take 3 arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (data,targ_vector,t):\n",
    "    test_lengths = int(t * len(data))\n",
    "    x_test = data[:test_lengths]\n",
    "    y_test = data[test_lengths:]\n",
    "    x_train = targ_vector[:test_lengths]\n",
    "    y_train = targ_vector[test_lengths:]\n",
    "    return x_test,y_test,x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Naively run your KNN_Classifier model on the trainingdataset with n_neighbors = 5 and using Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "{20.598909616470337}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "n_neighbor = 5\n",
    "weights = \"uniform\"\n",
    "KNN = KNN_Classifier ()\n",
    "KNN.fit(X,y,n_neighbor, weights)\n",
    "y_pred , y_test ,y_prob = KNN.predict(X)\n",
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "unstandardized = {}\n",
    "x = 0\n",
    "while x <= (len(model_args)-1):\n",
    "    Euclidean = model_args[x](y_pred, y_test)\n",
    "    unstandardized[x] = Euclidean\n",
    "    x += 1\n",
    "unstandardized   \n",
    "\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Use accuracy and F1 score to compare your predictions to the expected labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7475270843146491\n"
     ]
    }
   ],
   "source": [
    "print (\"F1 Score:\",unstandardized[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Now standardize each feature of your training set (subtract mean and divide by standard deviation). Use the mean and standard deviation values for each feature in the training set to scale the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardize = X.apply(lambda x: (x - x.mean(axis = 0) ) / (np.std(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Re-run the KNN_Classifier model on the standardized data, find the accuracy and F1 score with the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "{20.288357496261597}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "n_neighbor = 5\n",
    "weights = \"uniform\"\n",
    "KNN = KNN_Classifier ()\n",
    "KNN.fit(X_standardize,y,n_neighbor, weights)\n",
    "y_pred, y_test, y_prob = KNN.predict(X_standardize)\n",
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "standardized = {}\n",
    "x = 0\n",
    "while x <= (len(model_args)-1):\n",
    "    Euclidean = model_args[x](y_pred, y_test)\n",
    "    standardized[x] = Euclidean\n",
    "    x += 1\n",
    "    \n",
    "standardized\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Compare the two accuracy values and the F1 scores; and decide whether you should use standardized data or unscaled data for the remainder of the assignment. This will describedin the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the unstandardized to standardized 0.7475270843146491 0.791453785415699\n"
     ]
    }
   ],
   "source": [
    "print (\"Comparing the unstandardized to standardized\", unstandardized[3], standardized[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comapring the accuracy values from unstandardized to standardized (0.6596825396825396, 0.34031746031746035) (0.714920634920635, 0.28507936507936504)\n"
     ]
    }
   ],
   "source": [
    "print(\"Comapring the accuracy values from unstandardized to standardized\",unstandardized[4], standardized[4] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The decision being made is to use standardized values, because it produced a better F1 score as well as was more accurate compared to non standadrdized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Perform a similar test for inverse distance weighting in the KNN_Classifier model and determine whether or not to use it. This will go in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance\n",
      "{23.627888202667236}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_standardize = X.apply(lambda x: (x - x.mean(axis = 0) ) / (np.std(x)))\n",
    "n_neighbor = 5\n",
    "weights = \"distance\"\n",
    "KNN = KNN_Classifier ()\n",
    "KNN.fit(X_standardize,y,n_neighbor, weights)\n",
    "y_pred, y_test, y_prob = KNN.predict(X_standardize)\n",
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "standardized_weight = {}\n",
    "x = 0\n",
    "while x <= (len(model_args)-1):\n",
    "    Euclidean = model_args[x](y_pred, y_test)\n",
    "    standardized_weight[x] = Euclidean\n",
    "    x += 1\n",
    "    \n",
    "standardized_weight\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1,\n",
    "             4: accuracy_and_error} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight either uniform or distance using standardized weight 0.7904717853839038 0.7896389324960753\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight either uniform or distance using standardized weight\",standardized[3], standardized_weight[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight either uniform or distance using standardized weight (0.7123809523809523, 0.28761904761904766) (0.6594663278271918, 0.34053367217280817)\n"
     ]
    }
   ],
   "source": [
    "print(\"The weight either uniform or distance using standardized weight\",standardized[4], standardized_weight[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decision is to not use weights because they preform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>density</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>0.501792</td>\n",
       "      <td>-0.030828</td>\n",
       "      <td>-0.585335</td>\n",
       "      <td>-0.645247</td>\n",
       "      <td>0.552052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>-1.059523</td>\n",
       "      <td>1.942157</td>\n",
       "      <td>0.574937</td>\n",
       "      <td>0.177271</td>\n",
       "      <td>1.085403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>-1.388221</td>\n",
       "      <td>1.346474</td>\n",
       "      <td>0.768315</td>\n",
       "      <td>-0.125762</td>\n",
       "      <td>2.105725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>-0.319953</td>\n",
       "      <td>-0.375153</td>\n",
       "      <td>-0.585335</td>\n",
       "      <td>-0.125762</td>\n",
       "      <td>-0.491459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>1.159188</td>\n",
       "      <td>-1.359924</td>\n",
       "      <td>-0.972093</td>\n",
       "      <td>-0.515376</td>\n",
       "      <td>-0.190001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-0.402127</td>\n",
       "      <td>-0.409586</td>\n",
       "      <td>-0.391957</td>\n",
       "      <td>-0.385504</td>\n",
       "      <td>-0.932053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>0.666141</td>\n",
       "      <td>-1.029371</td>\n",
       "      <td>-0.585335</td>\n",
       "      <td>4.246571</td>\n",
       "      <td>-1.674106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>-1.470396</td>\n",
       "      <td>0.396136</td>\n",
       "      <td>0.333213</td>\n",
       "      <td>-0.212343</td>\n",
       "      <td>-0.259568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>-1.141698</td>\n",
       "      <td>2.314029</td>\n",
       "      <td>-0.101889</td>\n",
       "      <td>-0.039181</td>\n",
       "      <td>1.641942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>-0.237778</td>\n",
       "      <td>1.026252</td>\n",
       "      <td>0.574937</td>\n",
       "      <td>0.133981</td>\n",
       "      <td>0.273782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3961 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alcohol   density  volatile acidity  chlorides  total sulfur dioxide\n",
       "1513  0.501792 -0.030828         -0.585335  -0.645247              0.552052\n",
       "4748 -1.059523  1.942157          0.574937   0.177271              1.085403\n",
       "2244 -1.388221  1.346474          0.768315  -0.125762              2.105725\n",
       "4600 -0.319953 -0.375153         -0.585335  -0.125762             -0.491459\n",
       "2856  1.159188 -1.359924         -0.972093  -0.515376             -0.190001\n",
       "...        ...       ...               ...        ...                   ...\n",
       "869  -0.402127 -0.409586         -0.391957  -0.385504             -0.932053\n",
       "3902  0.666141 -1.029371         -0.585335   4.246571             -1.674106\n",
       "4378 -1.470396  0.396136          0.333213  -0.212343             -0.259568\n",
       "2411 -1.141698  2.314029         -0.101889  -0.039181              1.641942\n",
       "3814 -0.237778  1.026252          0.574937   0.133981              0.273782\n",
       "\n",
       "[3961 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use a helper function to calculate an s-partition of the data (i.e., partition the data into s equally sized portions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds (X, y, s):\n",
    "    features = np.array_split(X,s)\n",
    "    labels = np.array_split(y,s)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_values = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arg = dict(n_neighbor = 11, weights =\"uniform\")\n",
    "different_values[0] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 9, weights =\"uniform\")\n",
    "different_values[1] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 5, weights =\"uniform\")\n",
    "different_values[2] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 1, weights =\"uniform\")\n",
    "different_values[3] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 11, weights =\"distance\")\n",
    "different_values[4] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 9, weights =\"distance\")\n",
    "different_values[5] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 5, weights =\"distance\")\n",
    "different_values[6] = model_arg\n",
    "\n",
    "model_arg = dict(n_neighbor = 1, weights =\"distance\")\n",
    "different_values[7] = model_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Evaluation of an estimator performance via cross-validation: Implement the S-fold cross-validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sFold(k, X, y, model, model_args, model_arg, error_function):\n",
    "    KNN = KNN_Classifier()\n",
    "    KNN.fit(X, y, **model_arg)\n",
    "    Stored_dictionary_EU, Stored_dictionary_Ma = KNN.predict_folds(X,k)\n",
    "    x_fold= {}\n",
    "    every_case = {}\n",
    "    i = 0\n",
    "    while i <= (len(Stored_dictionary_EU)-1):\n",
    "        y_predEU, y_testEU, y_probEU = Stored_dictionary_EU[i]\n",
    "        y_predMa, y_testMa, y_probMa = Stored_dictionary_Ma[i]\n",
    "        x = 0\n",
    "        while x <= (len(model_args)-1):\n",
    "            Euclidean = np.round(model_args[x](y_predEU, y_testEU),4)\n",
    "            Manhatten = np.round(model_args[x](y_predMa, y_testMa),4)\n",
    "            x_fold[x] = Euclidean, Manhatten\n",
    "            x += 1\n",
    "        every_case[i] = x_fold\n",
    "        i += 1\n",
    "    return Stored_dictionary_EU, Stored_dictionary_Ma, every_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_Neighrbos = [1,5,9,11]\n",
    "weights = [\"uniform\",\"distance\"]\n",
    "for neighbor in Number_of_Neighrbos:\n",
    "    for values in weights:\n",
    "        Dictionary_EU, Dictionary_Ma, Error = sFold(5, X_standardize, y, KNN_Classifier(),model_args,F1,neighbor,values)\n",
    "        Euclidean_F1 = 0\n",
    "        Manhattan_F1 = 0\n",
    "        for values in Error:\n",
    "            F1_Score = Error[values][3]\n",
    "            Euclidean_F1 += F1_Score[0]\n",
    "            Manhattan_F1 += F1_Score[1]\n",
    "        F1_Eu = ((np.sum(Euclidean_F1))/5)\n",
    "        F1_Ma = ((np.sum(Manhattan_F1))/5)\n",
    "        print(\"number of neighbors:\",neighbor, \"weight:\", values, \"F1 Score of Euclidean and Manhattan\", F1_Eu, F1_Ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Use your sfold function to evaluate the performance of your model over each combination of k and distance metrics from the following sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below are the different versions of k, with a uniform distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{117.3985481262207}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x_test, x_train, y_test, y_train = partition (X,y,0.2)\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "K_11_Stored_dictionary_EU, K_11_Stored_dictionary_Ma, K_11_Error = sFold(5, x_train, y_train, \n",
    "                                                                         KNN_Classifier(),\n",
    "                                                                         model_args,different_values[0],\n",
    "                                                                         F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{117.21690011024475}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x_test, x_train, y_test, y_train = partition (X,y,0.2)\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "\n",
    "K_9_Stored_dictionary_EU, K_9_Stored_dictionary_Ma, K_9_Err = sFold(5, x_train, y_train,\n",
    "                                                                    KNN_Classifier(), \n",
    "                                                                    model_args,different_values[1], \n",
    "                                                                    F1Score )\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{116.58805179595947}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "K_5_Stored_dictionary_EU, K_5_Stored_dictionary_Ma, K_5_Err= sFold(5, x_train, y_train,\n",
    "                                                                    KNN_Classifier(), \n",
    "                                                                    model_args,  different_values[2],\n",
    "                                                                    F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{116.264155626297}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "K_1_Stored_dictionary_EU, K_1_Stored_dictionary_Ma, K_1_Err =  sFold(5, x_train, y_train,\n",
    "                                                                    KNN_Classifier(), \n",
    "                                                                    model_args, different_values[3],\n",
    "                                                                    F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the different variations of K, with a weighted distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{116.41165256500244}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error}  \n",
    "\n",
    "start = time.time()\n",
    "K_11_weight_Stored_dictionary_EU, K_11_weight_Stored_dictionary_Ma, K_11_weight_Err =  sFold(5, x_train, y_train,\n",
    "                                                                                             KNN_Classifier(),\n",
    "                                                                                             model_args,different_values[4],\n",
    "                                                                                             F1Score)\n",
    "end = time.time()\n",
    "print({end - start})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{116.40304398536682}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error}  \n",
    "K_9_weight_Stored_dictionary_EU, K_9_weight_Stored_dictionary_Ma, K_9_weight_Err = sFold(5,x_train, y_train,\n",
    "                                                                                         KNN_Classifier(),\n",
    "                                                                                         model_args,different_values[5],\n",
    "                                                                                         F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{118.87799310684204}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "K_5_Weight_Stored_dictionary_EU, K_5_Weight_Stored_dictionary_Ma, K_5_Weight_Err = sFold(5, x_train, y_train, KNN_Classifier(),\n",
    "                                                                                         model_args, different_values[6],F1Score) \n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{116.98287534713745}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "K_1_weight_Stored_dictionary_EU, K_1_weight_Stored_dictionary_Ma, K_1_weight_Err = sFold(5, x_train, y_train, KNN_Classifier(),\n",
    "                                                                                         model_args, different_values[7],F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_errors = [K_1_weight_Err,K_5_Weight_Err,K_9_weight_Err,K_11_weight_Err,K_1_Err,K_5_Err,K_9_Err,K_11_Error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_F1_error = {}\n",
    "i = 0\n",
    "for values in total_errors:\n",
    "    F1_Eu = 0\n",
    "    F1_Ma = 0\n",
    "    for value in values:\n",
    "        Error = values[value]\n",
    "        F1= Error[3]\n",
    "        F1_Eu += F1[0]\n",
    "        F1_Ma += F1[1] \n",
    "    F1_Eu = np.round((F1_Eu / 5),4)\n",
    "    F1_Ma = np.round((F1_Ma / 5),4)\n",
    "    Average_F1_error[i] = F1_Eu, F1_Ma\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the average F1_ error scores the intervals are k[1,5,9,11] and the split is weighted and none weighted. The euclidean distance , manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Calculate the average error (for all partitions) using the error_function on stored expected and predicted labels for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.7157, 0.722),\n",
       " 1: (0.7455, 0.7491),\n",
       " 2: (0.7461, 0.7497),\n",
       " 3: (0.7568, 0.7559),\n",
       " 4: (0.7157, 0.722),\n",
       " 5: (0.7681, 0.7678),\n",
       " 6: (0.7518, 0.7509),\n",
       " 7: (0.7491, 0.7644)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_F1_error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It would appear that the K = 11, weight = \"uniform\", folds = 5, using the Manhattan distance metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are the Proformance Measures \n",
    "for the different versions of ``K[1,5,9,11]`` and Distances. The values that are given are divided based upon the number of folds, Zero through 5. As well as within each fold they're divided via the different distance either (Euclidean or Manhatten). \n",
    "\n",
    "As well as the Different weights of either uniform or distance. These values are labeled with either ``_weight``. Or they don't have any which is means they are weighted via ```\"Uniform\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Evaluate your model on the test data and report the performance measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the readouts for each version of K and distance. This is just the first fold, but that can be changed via changing its index within the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([321,  94, 139,  76]), array([331,  95, 138,  66])),\n",
       " 1: (0.6978, 0.7058),\n",
       " 2: (0.8086, 0.8338),\n",
       " 3: (0.7491, 0.7644),\n",
       " 4: (array([0.6587, 0.3413]), array([0.6762, 0.3238]))}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_11_Error[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([321,  97, 136,  76]), array([321,  96, 137,  76])),\n",
       " 1: (0.7024, 0.7009),\n",
       " 2: (0.8086, 0.8086),\n",
       " 3: (0.7518, 0.7509),\n",
       " 4: (array([0.6635, 0.3365]), array([0.6619, 0.3381]))}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_9_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([323, 112, 121,  74]), array([324, 110, 123,  73])),\n",
       " 1: (0.7275, 0.7248),\n",
       " 2: (0.8136, 0.8161),\n",
       " 3: (0.7681, 0.7678),\n",
       " 4: (array([0.6905, 0.3095]), array([0.6889, 0.3111]))}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_5_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([292, 106, 127, 105]), array([296, 106, 127, 101])),\n",
       " 1: (0.6969, 0.6998),\n",
       " 2: (0.7355, 0.7456),\n",
       " 3: (0.7157, 0.722),\n",
       " 4: (array([0.6317, 0.3683]), array([0.6381, 0.3619]))}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_1_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([319, 106, 127,  78]), array([319, 105, 128,  78])),\n",
       " 1: (0.7152, 0.7136),\n",
       " 2: (0.8035, 0.8035),\n",
       " 3: (0.7568, 0.7559),\n",
       " 4: (array([0.6746, 0.3254]), array([0.673, 0.327]))}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_11_weight_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([313, 104, 129,  84]), array([316, 103, 130,  81])),\n",
       " 1: (0.7081, 0.7085),\n",
       " 2: (0.7884, 0.796),\n",
       " 3: (0.7461, 0.7497),\n",
       " 4: (array([0.6619, 0.3381]), array([0.6651, 0.3349]))}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_9_weight_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([309, 110, 123,  88]), array([312, 109, 124,  85])),\n",
       " 1: (0.7153, 0.7156),\n",
       " 2: (0.7783, 0.7859),\n",
       " 3: (0.7455, 0.7491),\n",
       " 4: (array([0.6651, 0.3349]), array([0.6683, 0.3317]))}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_5_Weight_Err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([292, 106, 127, 105]), array([296, 106, 127, 101])),\n",
       " 1: (0.6969, 0.6998),\n",
       " 2: (0.7355, 0.7456),\n",
       " 3: (0.7157, 0.722),\n",
       " 4: (array([0.6317, 0.3683]), array([0.6381, 0.3619]))}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_1_weight_Err[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K score of 11, non weighted, using the Euclidean Distance is provides the better results. ```K_11_Stored_dictionary_EU, K_11_Stored_dictionary_Ma, K_11_Error```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Evaluate your model on the test data and report the performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.7157, 0.722),\n",
       " 1: (0.7455, 0.7491),\n",
       " 2: (0.7461, 0.7497),\n",
       " 3: (0.7568, 0.7559),\n",
       " 4: (0.7157, 0.722),\n",
       " 5: (0.7681, 0.7678),\n",
       " 6: (0.7518, 0.7509),\n",
       " 7: (0.7491, 0.7644)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_F1_error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|F1 Scores|Euclidean Weighted|Manhattan Weighted|Euclidean|Manhattan|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|**K=1**|0.7157| 0.722|0.7157| 0.722|   \n",
    "|**K=5**|0.7455| 0.7491|0.7681| **0.7678**|\n",
    "|**K=9**|0.7461| 0.7497|0.7518| 0.7509| \n",
    "|**K=11**|0.7568| 0.7559|0.7491| 0.7644 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Precision|Euclidean Weighted|Manhattan Weighted|Euclidean|Manhattan|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|**K=1**| 0.6969| 0.6998 | 0.6969| 0.6998 | \n",
    "|**K=5**| 0.7153| 0.7156 | 0.7275| **0.7248** | \n",
    "|**K=9**| 0.7081| 0.7085 | 0.7024| 0.7009 |  \n",
    "|**K=11**| 0.7152| 0.7136 | 0.6978| 0.7058 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Recall|Euclidean Weighted|Manhattan Weighted|Euclidean|Manhattan|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|**K=1**| 0.7355| 0.7456 | 0.7355| 0.7456 | \n",
    "|**K=5**| 0.7783| 0.7859| 0.8136| **0.8161** | \n",
    "|**K=9**| 0.7884| 0.796 | 0.8086| 0.8086 |  \n",
    "|**K=11**| 0.8035| 0.8035 | 0.8086| 0.8338 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Accuracy, Error|Euclidean Weighted|Manhattan Weighted|Euclidean|Manhattan|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|**K=1**|0.6317, 0.3683 | 0.6381, 0.3619 |0.6317, 0.3683|0.6381, 0.3619| \n",
    "|**K=5**| 0.6651, 0.3349 | 0.6683, 0.3317 |**0.6905, 0.3095**|0.6889, 0.3111| \n",
    "|**K=9**| 0.6619, 0.3381 | 0.6651, 0.3349 |0.6635, 0.3365|0.6619, 0.3381|  \n",
    "|**K=11**| 0.6746, 0.3254 | 0.673, 0.327 |0.6587, 0.3413|0.6762, 0.3238| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the ROC curve and Determining the optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Generate the ROC curve and determine the optimal threshold. This will go in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions i've made just so that i won't have write out the line of code over \n",
    "# and over in order to determine the threshold. As well as it's very handy to have around.\n",
    "def Mean_Absolute_Error(a,b):\n",
    "    test = np.abs(a - b)\n",
    "    test = sum(test)\n",
    "    MAE = test / (len(a))\n",
    "    return MAE  \n",
    "def predict_threshold (a,b):\n",
    "    if b == 1:\n",
    "        return np.where((a <= b),0,1)\n",
    "    elif b == 0:\n",
    "        return np.where((a >= b),1,0)\n",
    "    else:\n",
    "        return np.where((a > b),1,0)\n",
    "def FalsePostiveRate(a,b):\n",
    "    TP , TN , FP ,FN = confusion_matrix(a,b)\n",
    "    if FP + TN == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (FP / (FP+TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "{184.71270632743835}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_args= {0:confusion_matrix,\n",
    "             1:precision,\n",
    "             2: recall, \n",
    "             3: F1Score,\n",
    "             4: accuracy_and_error} \n",
    "\n",
    "Optimal_Model_Eu, Optimal_Model_Ma, Optimal_Model_Error =  sFold(5, X_standardize, y,\n",
    "                                                                    KNN_Classifier(), \n",
    "                                                                    model_args, different_values[2],\n",
    "                                                                    F1Score)\n",
    "end = time.time()\n",
    "print({end - start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (array([426, 151, 141,  69]), array([423, 146, 146,  72])),\n",
       " 1: (0.7513, 0.7434),\n",
       " 2: (0.8606, 0.8545),\n",
       " 3: (0.8023, 0.7951),\n",
       " 4: (array([0.7332, 0.2668]), array([0.723, 0.277]))}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Optimal_Model_Error[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = list(np.array(list(range(0,105,5)))/100) \n",
    "Curves = ROC_Curve(Optimal_Model_Ma, thresholds)\n",
    "Area_Under_The_Curve = Area_Under_Curve(Curves)\n",
    "import matplotlib.pyplot as plt\n",
    "optimal_thresholds = []\n",
    "for values in Curves:\n",
    "    roc_curve = pd.DataFrame(Curves[values], columns = [\"x\",\"y\"])\n",
    "    j = roc_curve.y - roc_curve.x\n",
    "    optimal_threshold_roc = np.argmax(j)\n",
    "    optimal_threshold_ = thresholds[optimal_threshold_roc]\n",
    "    optimal_thresholds.append(optimal_threshold_)\n",
    "    plt.plot(roc_curve.x, roc_curve.y) \n",
    "    plt.title(\"Area Under the Curve\")\n",
    "    plt.ylabel('True Postive Rate')\n",
    "    plt.xlabel('False Postive Rate')\n",
    "    plt.plot([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal threshold value is  0.56\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold_value = (np.sum(optimal_thresholds))/5\n",
    "print(\"optimal threshold value is \" , optimal_threshold_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal threshold value for the ROC is 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute The AUC Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Compute the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7479688283346604,\n",
       " 0.7282020640956002,\n",
       " 0.7635218499501311,\n",
       " 0.7679184746505349,\n",
       " 0.748055901480559]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Area_Under_Curve(Curves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision_Recall_Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Generate the precision-recall curve and determine the optimal threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PR_Curve = Precision_Recall_Curve(Optimal_Model_Ma, thresholds)\n",
    "for values in PR_Curve:\n",
    "    curve = PR_Curve[values]\n",
    "    pr_curve = pd.DataFrame(curve, columns = [\"Recall\",\"Precision\"])\n",
    "    f = ((( 2 * (pr_curve.Recall * pr_curve.Precision))) / ((pr_curve.Recall + pr_curve.Precision)))\n",
    "    optimal_recall_curve = (np.argmax(f))/100\n",
    "    optimal_Precision_recall_curve.append(optimal_recall_curve)\n",
    "    pr_curve['thresholds'] = thresholds\n",
    "    plt.plot(pr_curve.thresholds, pr_curve.Recall, 'b') \n",
    "    plt.plot(pr_curve.thresholds, pr_curve.Precision, 'r')\n",
    "    plt.title(\"Precision Recall Curve\")\n",
    "    plt.xlabel('Threshold')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "optimal_thresholds = []\n",
    "for x in PR_Curve[0]:\n",
    "    difference = np.abs(x[0] - x[1])\n",
    "    differences.append(difference)\n",
    "for values in differences:\n",
    "    optimal_threshold = np.argsort(differences)[:5]\n",
    "    threshold = np.sum((optimal_threshold/20))/5\n",
    "    optimal_thresholds.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal threshold for precision recall curve is 0.58\n"
     ]
    }
   ],
   "source": [
    "optimal_precision_recall_threshold = (np.sum(optimal_thresholds)/ len(optimal_thresholds))\n",
    "print(\"optimal threshold for precision recall curve is\", optimal_precision_recall_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimal threshold for the precision curve is 0.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Error of 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Calculate and report the 95% confidence interval on the generalization error estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_Error_Storage = {}\n",
    "for values in Optimal_Model_Ma:\n",
    "    Fold = Optimal_Model_Ma[values]\n",
    "    y_prob = Fold[2]\n",
    "    y_test = Fold[1]\n",
    "    size_of_sample = y_test.shape[0]\n",
    "    y_prediction = predict_threshold(y_prob, .6) #a is the threshold we decided on last\n",
    "    accuracy, error = accuracy_and_error(y_prediction, y_test)\n",
    "    Standard_error = (1.96 *( np.sqrt((error *(1-error))/size_of_sample)))\n",
    "    CI_lower = np.round((error - Standard_error),4)\n",
    "    CI_upper = np.round((error + Standard_error),4)\n",
    "    CI_Error_Storage[values] = CI_lower,CI_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Confidence Interval 95%|Lower Bounds|Upper Bounds|\n",
    "|:---:|:---:|:---:|\n",
    "|**Fold 1**| 0.2823| 0.3471 |\n",
    "|**Fold 2**| 0.3207| 0.3875 |\n",
    "|**Fold 3**| 0.2835| 0.3485 |\n",
    "|**Fold 4**| 0.2531| 0.3162 |  \n",
    "|**Fold 5**| 0.2740| 0.3384 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.2823, 0.3471),\n",
       " 1: (0.3207, 0.3875),\n",
       " 2: (0.2835, 0.3485),\n",
       " 3: (0.2531, 0.3162),\n",
       " 4: (0.274, 0.3384)}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_Error_Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
